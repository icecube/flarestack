{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\texttt{flarestack}$ tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, be sure to follow the instructions of the [README](https://github.com/icecube/flarestack/blob/master/README.md) on how to install `flarestack`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n",
    "`flarestack` uses logging, so let's set the desired logging level. Typical logging levels, in order of verbosity, are `ERROR`, `WARNING`, `INFO`, `DEBUG`. If you are not familiar with python logging and/or you are more used to `print()` statements check out the [python logging HOWTO](https://docs.python.org/3/howto/logging.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flarestack` needs a local cache directory plus a source directory for the datasets. Normally, these are configured as environment variables (see `README`). Here, instead of using `export` from the shell, we set them from `python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "user = os.environ.get('USER')\n",
    "\n",
    "directory = 'Work'\n",
    "\n",
    "os.environ[\"FLARESTACK_SCRATCH_DIR\"] = os.path.join('/home', user, directory) \n",
    "os.environ[\"FLARESTACK_DATASET_DIR\"] = os.path.join('/home', user, directory, 'flarestack_datasets') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that the first `import` statement will trigger the creation of `flarestack` directory structure (this may be indeed unexpected from an `import`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flarestack.shared:Scratch Directory is: /home/lincetto/Work/flarestack__data/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/storage/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/cluster/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/pull_corrections/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/cluster/logs/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/catalogues/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/acceptance_functions/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/energy_pdf_splines/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/storage/pickles/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/plots/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/SoB_splines/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/analysis/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/plots/illustrations/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/catalogues/transients/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/bkg_splines/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/dataset_plots/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/unblinding_results/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/limits/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/pull_corrections/pulls/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/pull_corrections/floors/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/storage/cache/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/storage/cache/catalogue_cache/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/public_datasets/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/energy_proxy_weighting/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/dataset_plots/effective_area_plots/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/median_angular_resolution/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/dataset_plots/angular_resolution_plots/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/dataset_plots/energy_proxy_map/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/sim_datasets/\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "INFO:flarestack.data.icecube.ic_season:Loading datasets from /home/lincetto/Work/flarestack_datasets (local)\n"
     ]
    }
   ],
   "source": [
    "from flarestack.shared import host_server\n",
    "from flarestack.shared import fs_scratch_dir\n",
    "from flarestack.data.icecube.ic_season import icecube_dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now checking the environment configuration. The host server will be `None` if we are not running on the DESY or WIPAC clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at None with the following config:\n",
      " - data directory: /home/lincetto/Work/flarestack_datasets/\n",
      " - scratch directory: /home/lincetto/Work/flarestack__data/\n"
     ]
    }
   ],
   "source": [
    "print(f'Running at {host_server} with the following config:\\n - data directory: {icecube_dataset_dir}\\n - scratch directory: {fs_scratch_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Flarestack Classes\n",
    "\n",
    "Classes used in $\\texttt{flarestack}$'s core functionality (e.g. `flarestack.core.energy_pdf.EnergyPDF`, `flarestack.core.minimisation.MinimisationHandler`, etc) have a class attribute `<class>.subclasses`.  \n",
    "This is a dictionary with the structure `{<subclass name>: <subclass>}`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fixed_weights': flarestack.core.minimisation.FixedWeightMinimisationHandler,\n",
       " 'large_catalogue': flarestack.core.minimisation.LargeCatalogueMinimisationHandler,\n",
       " 'fit_weights': flarestack.core.minimisation.FitWeightMinimisationHandler,\n",
       " 'flare': flarestack.core.minimisation.FlareMinimisationHandler}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.core.minimisation import MinimisationHandler\n",
    "MinimisationHandler.subclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For analyses we only have to pass a dictionary of the subclass names and corresponding parameters.  \n",
    "To execute use `flarestack.cluster.submitter.Submitter`. This always works locally. For using the cluster, again, if you are running at DESY or WIPAC, you do not have to worry. We got you covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'local': flarestack.cluster.submitter.LocalSubmitter,\n",
       " 'DESY': flarestack.cluster.submitter.DESYSubmitter,\n",
       " 'WIPAC': flarestack.cluster.submitter.WIPACSubmitter}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.cluster.submitter import Submitter\n",
    "Submitter.submitter_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example: Point Source Sensitivity ##\n",
    "\n",
    "Let's try to calculate the 10-year point source sensitivity for one declination.  \n",
    "First we have to specify a name for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"analyses/10yr_ps_sens_one_declination\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input directory (with the analysis dictionaries), the output directory (plots, p-values, etc) and the cache directory (saved trials, etc) will be created accordingly. For example our plot output directory will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lincetto/Work/flarestack__data/output/plots/analyses/10yr_ps_sens_one_declination'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.shared import plot_output_dir\n",
    "plot_output_dir(name) # it is a name but also a path!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many dataset implementations are available in `flarestack.data`. We will use the PS Tracks v3.2.\n",
    "\n",
    "It is important to note that this is just and object-interface to the actual data set (that has to be previously made available in the designated directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.data.icecube import ps_v003_p02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to inject a steady neutrino signal with a power law spectrum with $\\gamma=2.5$. For other Energy or Time PDFs check `flarestack.core.energy_pdf` and `flarestack.core.time_pdf`.\n",
    "\n",
    "This is as straight forward as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "injection_gamma = 2.5\n",
    "\n",
    "injection_energy = {\n",
    "    \"energy_pdf_name\": \"power_law\",\n",
    "    \"gamma\": injection_gamma\n",
    "}\n",
    "\n",
    "injection_time = {\n",
    "    \"time_pdf_name\": \"steady\"\n",
    "}\n",
    "\n",
    "inj_setup = {\n",
    "    \"injection_energy_pdf\": injection_energy,\n",
    "    \"injection_sig_time_pdf\": injection_time\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for a steady signal with a power law spectrum. \n",
    "We assume the background to be constant in time.  \n",
    "We want to use the \"standard\" point source likelihood. More likelihood implementations in `flarestack.core.llh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh_time = {\n",
    "    \"time_pdf_name\": \"steady\"\n",
    "}\n",
    "\n",
    "llh_energy = {\n",
    "    \"energy_pdf_name\": \"power_law\",\n",
    "}\n",
    "\n",
    "llh_time_bkg = {\n",
    "    \"time_pdf_name\": \"steady\"\n",
    "}\n",
    "\n",
    "# here one can select \"llh_name\": \"spatial\" for spatial-only LLH ignoring energy and time PDFs\n",
    "llh_setup = {\n",
    "    \"llh_name\": \"standard\",\n",
    "    \"llh_energy_pdf\": llh_energy,\n",
    "    \"llh_sig_time_pdf\": llh_time,\n",
    "    \"llh_bkg_time_pdf\": llh_time_bkg\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a source catalogue. This catalogue will be a numpy array stored as a `.npy` file and we only pass the filename. For point sources the is a utility function to generate dummy sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue created at /home/lincetto/Work/flarestack__data/input/catalogues/single_source/sindec_0.50.npy\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from flarestack.utils.prepare_catalogue import ps_catalogue_name\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "This apparently innocuous function works behind the scenes to create a catalogue file, then returns its path. The numpy file contains a structured (array with named fields). We could create the array on-the-fly but having it stored is recommended and/or may be necessary afterwards.\n",
    "\"\"\"\n",
    "sindec = 0.5\n",
    "catalogue_path = ps_catalogue_name(sindec=sindec)\n",
    "print(f'Catalogue created at {catalogue_path}') # it could be better to have this logged!\n",
    "cat = np.load(catalogue_path)\n",
    "print(type(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(3.14159265, 0.52359878, 1., 1., 55800.4164699, 55750.4164699, 55900.4164699, 1., b'PS_dec=0.5')],\n",
       "      dtype=[('ra_rad', '<f8'), ('dec_rad', '<f8'), ('base_weight', '<f8'), ('injection_weight_modifier', '<f8'), ('ref_time_mjd', '<f8'), ('start_time_mjd', '<f8'), ('end_time_mjd', '<f8'), ('distance_mpc', '<f8'), ('source_name', 'S30')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a guess for our sensitivity.\n",
    "\n",
    "Note: $\\texttt{flarestack}$ is using its own flux unit $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1. equals to a dN/dE unit of 1e-09 (Gev)^-1 (s)^-1 (cm)^-2\n"
     ]
    }
   ],
   "source": [
    "from flarestack.shared import flux_to_k, k_to_flux\n",
    "\n",
    "print(f'k = 1. equals to a dN/dE unit of {k_to_flux(1.)} (Gev)^-1 (s)^-1 (cm)^-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we know where the sensitivity should be. Because the analysis has been done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flarestack.icecube_utils.reference_sensitivity:Retrieving reference sensititivity data from `ic_season` module\n"
     ]
    }
   ],
   "source": [
    "from flarestack.icecube_utils.reference_sensitivity import reference_sensitivity\n",
    "\n",
    "factor = 3. # we will scan a flux range up to three times the known reference\n",
    "ref_sens = reference_sensitivity(sindec, gamma=injection_gamma)\n",
    "scale = factor * flux_to_k(ref_sens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to put all the info into one dictionary to pass to the `MinimisationHanddler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_dict = {\n",
    "    \"name\": name,                               # unique name for the analysis\n",
    "    \"mh_name\": \"fixed_weights\",                 # name of the MinimisationHandler subcalss\n",
    "    \"dataset\": ps_v003_p02,                     # the neutrino dataset\n",
    "    \"catalogue\": catalogue_path,                # path to the .npy catalogue file\n",
    "    \"inj_dict\": inj_setup,                     # info for the Injector\n",
    "    \"llh_dict\": llh_setup,                     # info for the LLH\n",
    "    \"scale\": scale,                             # a guess for the sensitivity scale\n",
    "    \"n_trials\": 10,                             # number of trials to run (background trials will be run ten times this number!)\n",
    "    \"n_steps\": 10,                              # number of steps when injecting signal\n",
    "    \"allow_extrapolated_sensitivity\": True      # allow extrapolation in the sensitivity calculation (here we do because we only run very few trials)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the analysis we defined above we create a submitter instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:flarestack.cluster.submitter:No submitter implemented for host server None! Using LocalSubmitter but you wont't be able to use cluster operations!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Submitter for analyses/10yr_ps_sens_one_declination -----\n",
      "not using cluster \n",
      "using 1 CPUs locally\n",
      "job-id: None \n",
      "no scale estimation \n",
      "\n"
     ]
    }
   ],
   "source": [
    "submitter = Submitter.get_submitter(\n",
    "    mh_dict=mh_dict,                         # the analysis info\n",
    "    use_cluster=False,                       # run it on the cluster if True\n",
    "    n_cpu=1,                                 # number of LOCAL CPUs to use, NOTE: the number of cluster CPUs has to be specified in the cluster_kwargs!\n",
    "    do_sensitivity_scale_estimation=False,   # make a guess of the sensitivity scale, for options check flarestack.cluster.submitter\n",
    "    remove_old_results=True,                 # if you are running the analysis again and something changed, maybe you want to remove old trials?\n",
    "#   **cluster_kwargs                         # keyword arguments used when running the cluster, This depends on the cluster obviously\n",
    ")\n",
    "\n",
    "print(submitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energise ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:flarestack.cluster.submitter:Can not remove /home/lincetto/Work/flarestack__data/storage/pickles/analyses/10yr_ps_sens_one_declination! It is not a directory!\n",
      "WARNING:flarestack.cluster.submitter:Can not remove /home/lincetto/Work/flarestack__data/storage/pickles/injection_values/analyses/10yr_ps_sens_one_declination! It is not a directory!\n",
      "INFO:flarestack.core.minimisation:Using 'standard' LLH class\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lincetto/Work/flarestack_datasets/ps_tracks/version-003-p02/IC40_MC.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lincetto/Work/flarestack/examples/ipython_notebooks/New-Tutorial.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lincetto/Work/flarestack/examples/ipython_notebooks/New-Tutorial.ipynb#ch0000037?line=0'>1</a>\u001b[0m submitter\u001b[39m.\u001b[39;49manalyse()\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/cluster/submitter.py:236\u001b[0m, in \u001b[0;36mSubmitter.analyse\u001b[0;34m(self, do_disc)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmh_dict[\u001b[39m\"\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisc_guess \u001b[39m/\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[0;32m--> 236\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubmit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmh_dict)\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/cluster/submitter.py:88\u001b[0m, in \u001b[0;36mSubmitter.submit\u001b[0;34m(self, mh_dict)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubmit_cluster(mh_dict)\n\u001b[1;32m     87\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubmit_local(mh_dict)\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/cluster/submitter.py:80\u001b[0m, in \u001b[0;36mSubmitter.submit_local\u001b[0;34m(self, mh_dict)\u001b[0m\n\u001b[1;32m     78\u001b[0m make_analysis_pickle(mh_dict)\n\u001b[1;32m     79\u001b[0m n_cpu \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_cpu, os\u001b[39m.\u001b[39mcpu_count() \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m run_multiprocess(n_cpu\u001b[39m=\u001b[39;49mn_cpu, mh_dict\u001b[39m=\u001b[39;49mmh_dict)\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/core/multiprocess_wrapper.py:143\u001b[0m, in \u001b[0;36mrun_multiprocess\u001b[0;34m(n_cpu, mh_dict)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_multiprocess\u001b[39m(n_cpu, mh_dict):\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mwith\u001b[39;00m MultiProcessor(n_cpu\u001b[39m=\u001b[39;49mn_cpu, mh_dict\u001b[39m=\u001b[39;49mmh_dict) \u001b[39mas\u001b[39;00m r:\n\u001b[1;32m    144\u001b[0m         r\u001b[39m.\u001b[39mfill_queue()\n\u001b[1;32m    145\u001b[0m         r\u001b[39m.\u001b[39mterminate()\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/core/multiprocess_wrapper.py:58\u001b[0m, in \u001b[0;36mMultiProcessor.__init__\u001b[0;34m(self, n_cpu, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmh \u001b[39m=\u001b[39m MinimisationHandler\u001b[39m.\u001b[39mcreate(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmh_dict\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m season \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmh\u001b[39m.\u001b[39mseasons\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m---> 58\u001b[0m     inj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmh\u001b[39m.\u001b[39;49mget_injector(season)\n\u001b[1;32m     59\u001b[0m     inj\u001b[39m.\u001b[39mcalculate_n_exp()\n\u001b[1;32m     60\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmh_dict \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mmh_dict\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/core/minimisation.py:317\u001b[0m, in \u001b[0;36mMinimisationHandler.get_injector\u001b[0;34m(self, season_name)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_injector\u001b[39m(\u001b[39mself\u001b[39m, season_name):\n\u001b[1;32m    316\u001b[0m     \u001b[39mif\u001b[39;00m season_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_injectors\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m--> 317\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_injectors[season_name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_injector(\n\u001b[1;32m    318\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseasons[season_name], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minjection_sources\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    321\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_injectors[season_name]\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/core/minimisation.py:312\u001b[0m, in \u001b[0;36mMinimisationHandler.add_injector\u001b[0;34m(self, season, sources)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_injector\u001b[39m(\u001b[39mself\u001b[39m, season, sources):\n\u001b[0;32m--> 312\u001b[0m     \u001b[39mreturn\u001b[39;00m season\u001b[39m.\u001b[39;49mmake_injector(sources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minj_dict)\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/data/__init__.py:327\u001b[0m, in \u001b[0;36mSeasonWithMC.make_injector\u001b[0;34m(self, sources, **inj_kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_injector\u001b[39m(\u001b[39mself\u001b[39m, sources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minj_kwargs):\n\u001b[0;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m MCInjector\u001b[39m.\u001b[39;49mcreate(\u001b[39mself\u001b[39;49m, sources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minj_kwargs)\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/core/injector.py:200\u001b[0m, in \u001b[0;36mBaseInjector.create\u001b[0;34m(cls, season, sources, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m inj_dict \u001b[39m=\u001b[39m read_injector_dict(kwargs)\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minjector_name\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m inj_dict\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(season, sources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minj_dict)\n\u001b[1;32m    202\u001b[0m inj_name \u001b[39m=\u001b[39m inj_dict[\u001b[39m\"\u001b[39m\u001b[39minjector_name\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m inj_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m BaseInjector\u001b[39m.\u001b[39msubclasses:\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/core/injector.py:238\u001b[0m, in \u001b[0;36mMCInjector.__init__\u001b[0;34m(self, season, sources, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, season, sources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    237\u001b[0m     kwargs \u001b[39m=\u001b[39m read_injector_dict(kwargs)\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mc \u001b[39m=\u001b[39m season\u001b[39m.\u001b[39;49mget_mc()\n\u001b[1;32m    239\u001b[0m     BaseInjector\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, season, sources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minjection_declination_bandwidth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minj_kwargs\u001b[39m.\u001b[39mpop(\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minjection_declination_bandwidth\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1.5\u001b[39m\n\u001b[1;32m    243\u001b[0m     )\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/data/__init__.py:330\u001b[0m, in \u001b[0;36mSeasonWithMC.get_mc\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_mc\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 330\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmc_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/data/icecube/ic_season.py:292\u001b[0m, in \u001b[0;36mIceCubeSeason.load_data\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(\u001b[39mself\u001b[39m, path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mreturn\u001b[39;00m data_loader(path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/icecube_utils/dataset_loader.py:23\u001b[0m, in \u001b[0;36mdata_loader\u001b[0;34m(data_path, floor, cut_fields)\u001b[0m\n\u001b[1;32m     21\u001b[0m     dataset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(\u001b[39mtuple\u001b[39m([np\u001b[39m.\u001b[39mload(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data_path]))\n\u001b[1;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     dataset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(data_path, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msinDec\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mnames:\n\u001b[1;32m     27\u001b[0m     new_dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype([(\u001b[39m\"\u001b[39m\u001b[39msinDec\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mfloat\u001b[39m)])\n",
      "File \u001b[0;32m~/software/miniconda3/envs/flarestack/lib/python3.10/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lincetto/Work/flarestack_datasets/ps_tracks/version-003-p02/IC40_MC.npy'"
     ]
    }
   ],
   "source": [
    "submitter.analyse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the results we use the `ResultsHandler`. This will also create some plots like the sensitivity fit, bias plots, etc. in the plot directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.core.results import ResultsHandler\n",
    "results_handler = ResultsHandler(submitter.mh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fr'sensitivity flux: {results_handler.sensitivity:.2e} +{results_handler.sensitivity_err[1]}  -{results_handler.sensitivity_err[0]}')\n",
    "print(f'reference: {reference_sensitivity(sindec)[0]}')\n",
    "print(fr'sensitivity n_s: {results_handler.sensitivity * results_handler.flux_to_ns:.2e} +{results_handler.sensitivity_err[1] * results_handler.flux_to_ns}  -{results_handler.sensitivity_err[0] * results_handler.flux_to_ns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example: Upper Limits\n",
    "\n",
    "There are some really useful functions in `flarestack.cosmo`!  \n",
    "\n",
    "Take the implementations of the IceCube diffuse flux measurements for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.cosmo.icecube_diffuse_flux import contours, get_diffuse_flux_contour\n",
    "contours.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for fit in contours.keys():\n",
    "\n",
    "    best_fit, upper_butterfly, lower_butterfly, e_range = get_diffuse_flux_contour(fit)\n",
    "    plt.plot(e_range, best_fit(e_range) * e_range**2, label=fit)\n",
    "    plt.fill_between(e_range, upper_butterfly(e_range)* e_range**2, lower_butterfly(e_range)* e_range**2, alpha=0.3)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(r\"$E_{\\nu}$\")\n",
    "plt.ylabel(r\"$E_{\\nu}^{2} \\frac{dN}{dE}$\")\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.4), ncol=2, fancybox=True, shadow=True, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in transients you also are at the right place!  \n",
    "With your favourte transients population's rate, the flux normaisation at 1 GeV and the corresponding spectral index you can easily get the rate in a redshift shell, the neutrino flux per source at a certain redshift, the neutrino flux per redshift and the cumulatice neutrino flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.cosmo.neutrino_cosmology import define_cosmology_functions\n",
    "from flarestack.cosmo.rates import get_rate\n",
    "from astropy import units as u\n",
    "\n",
    "frb_rate = get_rate('FRB')\n",
    "frb_dummy_flux = 2e+46 / u.GeV\n",
    "frb_example_gamma = 2\n",
    "\n",
    "rate_per_z, nu_flux_per_z, nu_flux_per_source, cumulative_nu_flux = define_cosmology_functions(frb_rate, frb_dummy_flux, frb_example_gamma)\n",
    "\n",
    "redshift = np.linspace(0.1, 4, 1000)\n",
    "\n",
    "fig, axs = plt.subplots(4, sharex='all', figsize=[5, 12])\n",
    "axs[0].plot(redshift, rate_per_z(redshift).to('yr-1').value)\n",
    "axs[0].set_ylabel('rate [yr$^{-1}$]')\n",
    "\n",
    "axs[1].plot(redshift, nu_flux_per_z(redshift).to('GeV-1 cm-2 s-1 sr-1').value)\n",
    "axs[1].set_ylabel(r'$\\nu$ flux per redshift [GeV$^{-1}$ cm$^{-2}$]')\n",
    "\n",
    "axs[2].plot(redshift, nu_flux_per_source(redshift).to('GeV-1 cm-2').value)\n",
    "axs[2].set_ylabel(r'$\\nu$ flux per source [GeV$^{-1}$ cm$^{-2}$]')\n",
    "\n",
    "axs[3].plot(redshift[1:-1], [i.to('1 / (cm2 GeV s sr)').value for i in cumulative_nu_flux(redshift)])\n",
    "axs[3].set_ylabel(r'cumulative $\\nu$ flux [GeV$^{-1}$ cm$^{-2}$]')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The result of `cumulative_nu_flux()` is already your result for the contribution of the popultion to the diffuse flux!  \n",
    "\n",
    "All the above is packed into one convenience function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.cosmo.neutrino_cosmology import calculate_transient_cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this to get some actual super interesting, timely results and revisit the FRB  asscociated with the galactic Magnetar SGR 1935+2154 (https://arxiv.org/abs/2005.10828).  \n",
    "IceCube performed a search for neutrinos and found upper limits:\n",
    "```\n",
    "IceCube Limit is E^2 dN/dE = 5.2 × 10−2 GeV cm^-2 @ 1 GeV \n",
    "```\n",
    "(http://www.astronomerstelegram.org/?read=13689)  \\\n",
    "The Magnetar is 16 kpc away (conservative). Let's assume a spectrum with $\\gamma=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.core.energy_pdf import EnergyPDF\n",
    "\n",
    "dist = 16 * u.kpc\n",
    "atel_flux_norm_lim = 5.2 * 10**-2. * (u. GeV / u.cm**2) / u.GeV**2.\n",
    "\n",
    "e_pdf_dict = {\n",
    "    \"energy_pdf_name\": \"power_law\",\n",
    "    \"gamma\": 2.0,\n",
    "    \"e_min_gev\": 10.**3,\n",
    "    \"e_max_gev\": 10.**6,\n",
    "    \"nu_flux_at_1_gev\": atel_flux_norm_lim * 4 * np.pi * dist**2.\n",
    "}\n",
    "\n",
    "epdf = EnergyPDF.create(e_pdf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these information it is now super straight forward to get the upper limits from a population of FRB's, that share SGR 1935+2154's properties, assuming they are all standard candels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = \"joint_15\"\n",
    "integrated_nu_flux_1_gev = calculate_transient_cosmology(e_pdf_dict, frb_rate, \"frb_limit\", zmax=8.0, diffuse_fit=fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our very interesting findings so we can publish in a prestegious journal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit, upper_butterfly, lower_butterfly, e_range = get_diffuse_flux_contour(fit=fit)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(e_range, best_fit(e_range) * e_range**2, label=\"IceCube Diffuse Flux\")\n",
    "plt.fill_between(e_range, upper_butterfly(e_range)* e_range**2, lower_butterfly(e_range)* e_range**2, alpha=0.3)\n",
    "x = [epdf.e_min, np.exp(0.5*(np.log(epdf.e_min) + np.log(epdf.e_max))), epdf.e_max]\n",
    "y = np.array([integrated_nu_flux_1_gev.value for _ in range(3)]) \n",
    "plt.errorbar(x, y, yerr=0.25*y, uplims=True, label='limit')\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(r\"$E_{\\nu} [GeV] $\")\n",
    "plt.ylabel(r\"$E_{\\nu}^{2} \\frac{dN}{dE}$ [GeV cm$^{-2}$ s$^{-1}$ sr$^{-1}$]\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('flarestack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "00e5c047db1c3f47b2e42de94401643a778179f76b842f59cbffe62762772fde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
