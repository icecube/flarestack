{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\texttt{flarestack}$ tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, be sure to follow the instructions of the [README](https://github.com/icecube/flarestack/blob/master/README.md) on how to install `flarestack`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n",
    "`flarestack` uses logging, so let's set the desired logging level. Typical logging levels, in order of verbosity, are `ERROR`, `WARNING`, `INFO`, `DEBUG`. If you are not familiar with python logging and/or you are more used to `print()` statements check out the [python logging HOWTO](https://docs.python.org/3/howto/logging.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flarestack` needs a local cache directory plus a source directory for the datasets. Normally, these are configured as environment variables (see `README`). Here, instead of using `export` from the shell, we set them from `python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "user = os.environ.get('USER')\n",
    "\n",
    "directory = 'Work'\n",
    "\n",
    "os.environ[\"FLARESTACK_SCRATCH_DIR\"] = os.path.join('/home', user, directory) \n",
    "os.environ[\"FLARESTACK_DATASET_DIR\"] = os.path.join('/home', user, directory, 'flarestack_datasets') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that the first `import` statement will trigger the creation of `flarestack` directory structure (this may be indeed unexpected from an `import`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flarestack.shared:Scratch Directory is: /home/lincetto/Work/flarestack__data/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/storage/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/cluster/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/pull_corrections/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/cluster/logs/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/catalogues/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/acceptance_functions/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/energy_pdf_splines/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/storage/pickles/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/plots/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/SoB_splines/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/analysis/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/plots/illustrations/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/catalogues/transients/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/bkg_splines/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/dataset_plots/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/unblinding_results/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/limits/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/pull_corrections/pulls/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/pull_corrections/floors/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/storage/cache/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/storage/cache/catalogue_cache/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/public_datasets/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/energy_proxy_weighting/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/dataset_plots/effective_area_plots/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/median_angular_resolution/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/dataset_plots/angular_resolution_plots/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/output/dataset_plots/energy_proxy_map/\n",
      "INFO:flarestack.shared:Found Directory: /home/lincetto/Work/flarestack__data/input/sim_datasets/\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "INFO:flarestack.data.icecube.ic_season:Loading datasets from /home/lincetto/Work/flarestack_datasets (local)\n"
     ]
    }
   ],
   "source": [
    "from flarestack.shared import host_server\n",
    "from flarestack.shared import fs_scratch_dir\n",
    "from flarestack.data.icecube.ic_season import icecube_dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now checking the environment configuration. The host server will be `None` if we are not running on the DESY or WIPAC clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at None with the following config:\n",
      " - data directory: /home/lincetto/Work/flarestack_datasets\n",
      " - scratch directory: /home/lincetto/Work/flarestack__data/\n"
     ]
    }
   ],
   "source": [
    "print(f'Running at {host_server} with the following config:\\n - data directory: {icecube_dataset_dir}\\n - scratch directory: {fs_scratch_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Flarestack Classes\n",
    "\n",
    "Classes used in $\\texttt{flarestack}$'s core functionality (e.g. `flarestack.core.energy_pdf.EnergyPDF`, `flarestack.core.minimisation.MinimisationHandler`, etc) have a class attribute `<class>.subclasses`.  \n",
    "This is a dictionary with the structure `{<subclass name>: <subclass>}`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fixed_weights': flarestack.core.minimisation.FixedWeightMinimisationHandler,\n",
       " 'large_catalogue': flarestack.core.minimisation.LargeCatalogueMinimisationHandler,\n",
       " 'fit_weights': flarestack.core.minimisation.FitWeightMinimisationHandler,\n",
       " 'flare': flarestack.core.minimisation.FlareMinimisationHandler}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.core.minimisation import MinimisationHandler\n",
    "MinimisationHandler.subclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For analyses we only have to pass a dictionary of the subclass names and corresponding parameters.  \n",
    "To execute use `flarestack.cluster.submitter.Submitter`. This always works locally. For using the cluster, again, if you are running at DESY or WIPAC, you do not have to worry. We got you covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'local': flarestack.cluster.submitter.LocalSubmitter,\n",
       " 'DESY': flarestack.cluster.submitter.DESYSubmitter,\n",
       " 'WIPAC': flarestack.cluster.submitter.WIPACSubmitter}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.cluster.submitter import Submitter\n",
    "Submitter.submitter_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example: Point Source Sensitivity ##\n",
    "\n",
    "Let's try to calculate the 10-year point source sensitivity for one declination.  \n",
    "First we have to specify a name for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"analyses/10yr_ps_sens_one_declination\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input directory (with the analysis dictionaries), the output directory (plots, p-values, etc) and the cache directory (saved trials, etc) will be created accordingly. For example our plot output directory will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lincetto/Work/flarestack__data/output/plots/analyses/10yr_ps_sens_one_declination'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.shared import plot_output_dir\n",
    "plot_output_dir(name) # it is a name but also a path!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many dataset implementations are available in `flarestack.data`. We will use the PS Tracks v3.2.\n",
    "\n",
    "It is important to note that this is just and object-interface to the actual data set (that has to be previously made available in the designated directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.data.icecube import ps_v003_p02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to inject a steady neutrino signal with a power law spectrum with $\\gamma=2.5$. For other Energy or Time PDFs check `flarestack.core.energy_pdf` and `flarestack.core.time_pdf`.\n",
    "\n",
    "This is as straight forward as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "injection_gamma = 2.5\n",
    "\n",
    "injection_energy = {\n",
    "    \"energy_pdf_name\": \"power_law\",\n",
    "    \"gamma\": injection_gamma\n",
    "}\n",
    "\n",
    "injection_time = {\n",
    "    \"time_pdf_name\": \"steady\"\n",
    "}\n",
    "\n",
    "injection_config = {\n",
    "    \"injection_energy_pdf\": injection_energy,\n",
    "    \"injection_sig_time_pdf\": injection_time\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for a steady signal with a power law spectrum. \n",
    "We assume the background to be constant in time.  \n",
    "We want to use the \"standard\" point source likelihood. More likelihood implementations in `flarestack.core.llh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh_time = {\n",
    "    \"time_pdf_name\": \"steady\"\n",
    "}\n",
    "\n",
    "llh_energy = {\n",
    "    \"energy_pdf_name\": \"power_law\",\n",
    "}\n",
    "\n",
    "llh_time_bkg = {\n",
    "    \"time_pdf_name\": \"steady\"\n",
    "}\n",
    "\n",
    "# here one can select \"llh_name\": \"spatial\" for spatial-only LLH ignoring energy and time PDFs\n",
    "llh_config = {\n",
    "    \"llh_name\": \"standard\",\n",
    "    \"llh_energy_pdf\": llh_energy,\n",
    "    \"llh_sig_time_pdf\": llh_time,\n",
    "    \"llh_bkg_time_pdf\": llh_time_bkg\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a source catalogue. This catalogue will be a numpy array stored as a `.npy` file and we only pass the filename. For point sources the is a utility function to generate dummy sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue created at /home/lincetto/Work/flarestack__data/input/catalogues/single_source/sindec_0.50.npy\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from flarestack.utils.prepare_catalogue import ps_catalogue_name\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "This apparently innocuous function works behind the scenes to create a catalogue file, then returns its path. The numpy file contains a structured (array with named fields). We could create the array on-the-fly but having it stored is recommended and/or may be necessary afterwards.\n",
    "\"\"\"\n",
    "sindec = 0.5\n",
    "catalogue_path = ps_catalogue_name(sindec=sindec)\n",
    "print(f'Catalogue created at {catalogue_path}') # it could be better to have this logged!\n",
    "cat = np.load(catalogue_path)\n",
    "print(type(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(3.14159265, 0.52359878, 1., 1., 55800.4164699, 55750.4164699, 55900.4164699, 1., b'PS_dec=0.5')],\n",
       "      dtype=[('ra_rad', '<f8'), ('dec_rad', '<f8'), ('base_weight', '<f8'), ('injection_weight_modifier', '<f8'), ('ref_time_mjd', '<f8'), ('start_time_mjd', '<f8'), ('end_time_mjd', '<f8'), ('distance_mpc', '<f8'), ('source_name', 'S30')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a guess for our sensitivity.\n",
    "\n",
    "Note: $\\texttt{flarestack}$ is using its own flux unit $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1. equals to a dN/dE unit of 1e-09 (Gev)^-1 (s)^-1 (cm)^-2\n"
     ]
    }
   ],
   "source": [
    "from flarestack.shared import flux_to_k, k_to_flux\n",
    "\n",
    "print(f'k = 1. equals to a dN/dE unit of {k_to_flux(1.)} (Gev)^-1 (s)^-1 (cm)^-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we know where the sensitivity should be. Because the analysis has been done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No reference sensitivity directory found. Please create one at /home/lincetto/Work/flarestack_datasets/mirror-7year-PS-sens/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/lincetto/Work/flarestack/examples/ipython_notebooks/New-Tutorial.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lincetto/Work/flarestack/examples/ipython_notebooks/New-Tutorial.ipynb#ch0000031?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflarestack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39micecube_utils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreference_sensitivity\u001b[39;00m \u001b[39mimport\u001b[39;00m reference_sensitivity\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lincetto/Work/flarestack/examples/ipython_notebooks/New-Tutorial.ipynb#ch0000031?line=2'>3</a>\u001b[0m factor \u001b[39m=\u001b[39m \u001b[39m3.\u001b[39m \u001b[39m# we will scan a flux range up to three times the known reference\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lincetto/Work/flarestack/examples/ipython_notebooks/New-Tutorial.ipynb#ch0000031?line=3'>4</a>\u001b[0m ref_sens \u001b[39m=\u001b[39m reference_sensitivity(sindec, gamma\u001b[39m=\u001b[39minjection_gamma)\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/icecube_utils/reference_sensitivity.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpolate\u001b[39;00m \u001b[39mimport\u001b[39;00m interp1d, interp2d\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflarestack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39micecube\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mic_season\u001b[39;00m \u001b[39mimport\u001b[39;00m get_published_sens_ref_dir\n\u001b[0;32m----> 6\u001b[0m ref_dir_7yr, ref_10yr \u001b[39m=\u001b[39m get_published_sens_ref_dir()\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreference_sensitivity\u001b[39m(sindec\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(\u001b[39m0.0\u001b[39m), gamma\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m, sample\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m7yr\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m sample \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m7yr\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Work/flarestack/flarestack/data/icecube/ic_season.py:64\u001b[0m, in \u001b[0;36mget_published_sens_ref_dir\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m error_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo reference sensitivity directory found. Please create one at \u001b[39m\u001b[39m{\u001b[39;00micecube_dataset_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/mirror-7year-PS-sens/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[39m#logger.error(error_msg)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No reference sensitivity directory found. Please create one at /home/lincetto/Work/flarestack_datasets/mirror-7year-PS-sens/"
     ]
    }
   ],
   "source": [
    "from flarestack.icecube_utils.reference_sensitivity import reference_sensitivity\n",
    "\n",
    "factor = 3. # we will scan a flux range up to three times the known reference\n",
    "ref_sens = reference_sensitivity(sindec, gamma=injection_gamma)\n",
    "scale = factor * flux_to_k(ref_sens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to put all the info into one dictionary to pass to the `MinimisationHanddler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_dict = {\n",
    "    \"name\": name,                               # unique name for the analysis\n",
    "    \"mh_name\": \"fixed_weights\",                 # name of the MinimisationHandler subcalss\n",
    "    \"dataset\": ps_v003_p02,                     # the neutrino dataset\n",
    "    \"catalogue\": catalogue_path,                # path to the .npy catalogue file\n",
    "    \"inj_dict\": inj_kwargs,                     # info for the Injector\n",
    "    \"llh_dict\": llh_kwargs,                     # info for the LLH\n",
    "    \"scale\": scale,                             # a guess for the sensitivity scale\n",
    "    \"n_trials\": 10,                             # number of trials to run (background trials will be run ten times this number!)\n",
    "    \"n_steps\": 10,                              # number of steps when injecting signal\n",
    "    \"allow_extrapolated_sensitivity\": True      # allow extrapolation in the sensitivity calculation (here we do because we only run very few trials)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the analysis we defined above we create a submitter instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitter = Submitter.get_submitter(\n",
    "    mh_dict=mh_dict,                         # the analysis info\n",
    "    use_cluster=False,                       # run it on the cluster if True\n",
    "    n_cpu=1,                                 # number of LOCAL CPUs to use, NOTE: the number of cluster CPUs has to be specified in the cluster_kwargs!\n",
    "    do_sensitivity_scale_estimation=False,   # make a guess of the sensitivity scale, for options check flarestack.cluster.submitter\n",
    "    remove_old_results=True,                 # if you are running the analysis again and something changed, maybe you want to remove old trials?\n",
    "#   **cluster_kwargs                         # keyword arguments used when running the cluster, This depends on the cluster obviously\n",
    ")\n",
    "\n",
    "print(submitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energise ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitter.analyse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the results we use the `ResultsHandler`. This will also create some plots like the sensitivity fit, bias plots, etc. in the plot directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.core.results import ResultsHandler\n",
    "results_handler = ResultsHandler(submitter.mh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fr'sensitivity flux: {results_handler.sensitivity:.2e} +{results_handler.sensitivity_err[1]}  -{results_handler.sensitivity_err[0]}')\n",
    "print(f'reference: {reference_sensitivity(sindec)[0]}')\n",
    "print(fr'sensitivity n_s: {results_handler.sensitivity * results_handler.flux_to_ns:.2e} +{results_handler.sensitivity_err[1] * results_handler.flux_to_ns}  -{results_handler.sensitivity_err[0] * results_handler.flux_to_ns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example: Upper Limits\n",
    "\n",
    "There are some really useful functions in `flarestack.cosmo`!  \n",
    "\n",
    "Take the implementations of the IceCube diffuse flux measurements for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.cosmo.icecube_diffuse_flux import contours, get_diffuse_flux_contour\n",
    "contours.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for fit in contours.keys():\n",
    "\n",
    "    best_fit, upper_butterfly, lower_butterfly, e_range = get_diffuse_flux_contour(fit)\n",
    "    plt.plot(e_range, best_fit(e_range) * e_range**2, label=fit)\n",
    "    plt.fill_between(e_range, upper_butterfly(e_range)* e_range**2, lower_butterfly(e_range)* e_range**2, alpha=0.3)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(r\"$E_{\\nu}$\")\n",
    "plt.ylabel(r\"$E_{\\nu}^{2} \\frac{dN}{dE}$\")\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.4), ncol=2, fancybox=True, shadow=True, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in transients you also are at the right place!  \n",
    "With your favourte transients population's rate, the flux normaisation at 1 GeV and the corresponding spectral index you can easily get the rate in a redshift shell, the neutrino flux per source at a certain redshift, the neutrino flux per redshift and the cumulatice neutrino flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.cosmo.neutrino_cosmology import define_cosmology_functions\n",
    "from flarestack.cosmo.rates import get_rate\n",
    "from astropy import units as u\n",
    "\n",
    "frb_rate = get_rate('FRB')\n",
    "frb_dummy_flux = 2e+46 / u.GeV\n",
    "frb_example_gamma = 2\n",
    "\n",
    "rate_per_z, nu_flux_per_z, nu_flux_per_source, cumulative_nu_flux = define_cosmology_functions(frb_rate, frb_dummy_flux, frb_example_gamma)\n",
    "\n",
    "redshift = np.linspace(0.1, 4, 1000)\n",
    "\n",
    "fig, axs = plt.subplots(4, sharex='all', figsize=[5, 12])\n",
    "axs[0].plot(redshift, rate_per_z(redshift).to('yr-1').value)\n",
    "axs[0].set_ylabel('rate [yr$^{-1}$]')\n",
    "\n",
    "axs[1].plot(redshift, nu_flux_per_z(redshift).to('GeV-1 cm-2 s-1 sr-1').value)\n",
    "axs[1].set_ylabel(r'$\\nu$ flux per redshift [GeV$^{-1}$ cm$^{-2}$]')\n",
    "\n",
    "axs[2].plot(redshift, nu_flux_per_source(redshift).to('GeV-1 cm-2').value)\n",
    "axs[2].set_ylabel(r'$\\nu$ flux per source [GeV$^{-1}$ cm$^{-2}$]')\n",
    "\n",
    "axs[3].plot(redshift[1:-1], [i.to('1 / (cm2 GeV s sr)').value for i in cumulative_nu_flux(redshift)])\n",
    "axs[3].set_ylabel(r'cumulative $\\nu$ flux [GeV$^{-1}$ cm$^{-2}$]')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The result of `cumulative_nu_flux()` is already your result for the contribution of the popultion to the diffuse flux!  \n",
    "\n",
    "All the above is packed into one convenience function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.cosmo.neutrino_cosmology import calculate_transient_cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this to get some actual super interesting, timely results and revisit the FRB  asscociated with the galactic Magnetar SGR 1935+2154 (https://arxiv.org/abs/2005.10828).  \n",
    "IceCube performed a search for neutrinos and found upper limits:\n",
    "```\n",
    "IceCube Limit is E^2 dN/dE = 5.2 × 10−2 GeV cm^-2 @ 1 GeV \n",
    "```\n",
    "(http://www.astronomerstelegram.org/?read=13689)  \\\n",
    "The Magnetar is 16 kpc away (conservative). Let's assume a spectrum with $\\gamma=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.core.energy_pdf import EnergyPDF\n",
    "\n",
    "dist = 16 * u.kpc\n",
    "atel_flux_norm_lim = 5.2 * 10**-2. * (u. GeV / u.cm**2) / u.GeV**2.\n",
    "\n",
    "e_pdf_dict = {\n",
    "    \"energy_pdf_name\": \"power_law\",\n",
    "    \"gamma\": 2.0,\n",
    "    \"e_min_gev\": 10.**3,\n",
    "    \"e_max_gev\": 10.**6,\n",
    "    \"nu_flux_at_1_gev\": atel_flux_norm_lim * 4 * np.pi * dist**2.\n",
    "}\n",
    "\n",
    "epdf = EnergyPDF.create(e_pdf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these information it is now super straight forward to get the upper limits from a population of FRB's, that share SGR 1935+2154's properties, assuming they are all standard candels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = \"joint_15\"\n",
    "integrated_nu_flux_1_gev = calculate_transient_cosmology(e_pdf_dict, frb_rate, \"frb_limit\", zmax=8.0, diffuse_fit=fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our very interesting findings so we can publish in a prestegious journal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit, upper_butterfly, lower_butterfly, e_range = get_diffuse_flux_contour(fit=fit)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(e_range, best_fit(e_range) * e_range**2, label=\"IceCube Diffuse Flux\")\n",
    "plt.fill_between(e_range, upper_butterfly(e_range)* e_range**2, lower_butterfly(e_range)* e_range**2, alpha=0.3)\n",
    "x = [epdf.e_min, np.exp(0.5*(np.log(epdf.e_min) + np.log(epdf.e_max))), epdf.e_max]\n",
    "y = np.array([integrated_nu_flux_1_gev.value for _ in range(3)]) \n",
    "plt.errorbar(x, y, yerr=0.25*y, uplims=True, label='limit')\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(r\"$E_{\\nu} [GeV] $\")\n",
    "plt.ylabel(r\"$E_{\\nu}^{2} \\frac{dN}{dE}$ [GeV cm$^{-2}$ s$^{-1}$ sr$^{-1}$]\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('flarestack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "00e5c047db1c3f47b2e42de94401643a778179f76b842f59cbffe62762772fde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
